# ğŸ§  Deep Learning â€“ GÃ©nÃ©ration dâ€™Images Ã  Partir de Classes Cibles

Ce projet explore une approche inverse de la classification : **plutÃ´t que de prÃ©dire une classe Ã  partir dâ€™une image, nous cherchons Ã  gÃ©nÃ©rer une image qui maximise la probabilitÃ© dâ€™appartenance Ã  une classe cible donnÃ©e**. Cela permet dâ€™interprÃ©ter ce que le modÃ¨le a rÃ©ellement appris.

---

## ğŸ“ Contenu du dÃ©pÃ´t

- `notebook_classificateur_generateur.ipynb` : Notebook Jupyter complet et commentÃ©, incluant :
  - EntraÃ®nement dâ€™un CNN sur MNIST
  - Ã‰tude dâ€™ablation
  - Comparaison avec k-NN et rÃ©gression logistique
  - Analyse des scores de confiance et des quantiles
  - Optimisation inversÃ©e dâ€™images (CNN et k-NN)

- `rapport_projet_classificateur_generateur.pdf` : Rapport de synthÃ¨se dÃ©taillÃ© avec explications thÃ©oriques, rÃ©sultats expÃ©rimentaux, et pistes dâ€™amÃ©lioration.

---

## ğŸ¯ Objectifs 

- Comprendre lâ€™architecture dâ€™un CNN et son fonctionnement sur le dataset MNIST
- Visualiser les dÃ©cisions du modÃ¨le Ã  travers lâ€™optimisation dâ€™entrÃ©es
- Comparer la qualitÃ© des prÃ©dictions et la calibration des probabilitÃ©s
- Tester la robustesse du modÃ¨le avec des mÃ©thodes alternatives

---

## ğŸ“Š ModÃ¨les comparÃ©s

| ModÃ¨le                  | Accuracy | Observations |
|------------------------|----------|--------------|
| CNN                    | 99.00 %  | TrÃ¨s confiant et prÃ©cis |
| k-NN                   | 96.88 %  | ProbabilitÃ©s discrÃ¨tes, moins nuancÃ© |
| RÃ©gression Logistique  | 92.58 %  | Moins prÃ©cis mais meilleure gestion des incertitudes |

---

## ğŸ’¡ Optimisation InversÃ©e

Nous cherchons une image \( x \) telle que \( p_i(x) \) soit maximal, via gradient ascent dans le cas du CNN, ou approximation heuristique dans le cas du k-NN.

Cela permet de **visualiser la reprÃ©sentation interne du modÃ¨le** pour une classe cible, et dâ€™Ã©valuer ses biais potentiels.

---

## ğŸ“Œ Auteurs

Projet rÃ©alisÃ© en binÃ´me dans le cadre du cours de Deep Learning 2024-2025 :
- Arnaud ChÃ©ridi
- Wayan Crain
- Yanis Aoudjit

---

## ğŸ§­ Pistes dâ€™amÃ©lioration

- Ã‰tendre Ã  dâ€™autres datasets (CIFAR-10, F-MNIST)
- Ã‰tudier dâ€™autres modÃ¨les (SVM, Random Forest)
- Ã‰valuer la robustesse face au bruit et aux perturbations adversariales
- Applications potentielles : reconnaissance dâ€™Ã©criture manuscrite universitaire
